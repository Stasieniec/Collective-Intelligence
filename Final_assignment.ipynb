{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_data(num_entries, num_rows, filename):\n",
    "    # Open the file for writing\n",
    "    with open(filename, 'w') as file:\n",
    "        # Generate each row\n",
    "        for _ in range(num_rows):\n",
    "            # Generate each entry in the row as a list of 3 random integers\n",
    "            row = [f\"[{random.randint(10, 60)}, {random.randint(10, 60)}, {random.randint(10, 60)}]\" for _ in range(num_entries)]\n",
    "            # Join all entries into a single string with commas and write to file\n",
    "            formatted_row = ', '.join(row)\n",
    "            file.write(f\"\\\"{formatted_row}\\\"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "generate_data(4, 6, 'fake_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load and parse the CSV data\n",
    "def load_and_parse_data(file_path):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    sequences = []\n",
    "    for index, row in data.iterrows():\n",
    "        # Convert the row from string representation to list of lists of integers\n",
    "        sequence = ast.literal_eval(row[0])\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Split sequences into input and target\n",
    "def split_sequences(sequences):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for seq in sequences:\n",
    "        mid = len(seq) // 2\n",
    "        inputs.append(seq[:mid])\n",
    "        targets.append(seq[mid:])\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "# Load and preprocess the data\n",
    "file_path = 'fake_data.csv'  # replace with your file path\n",
    "sequences = load_and_parse_data(file_path)\n",
    "inputs, targets = split_sequences(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, 3)]            0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None, 3)]            0         []                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 50),                 10800     ['input_1[0][0]']             \n",
      "                              (None, 50),                                                         \n",
      "                              (None, 50)]                                                         \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 50),           10800     ['input_2[0][0]',             \n",
      "                              (None, 50),                            'lstm[0][1]',                \n",
      "                              (None, 50)]                            'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 3)              153       ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21753 (84.97 KB)\n",
      "Trainable params: 21753 (84.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# Define the model parameters\n",
    "num_features = 3  # Since each element in the sequence is a list of 3 integers\n",
    "latent_dim = 50  # Latent dimensionality of the encoding space\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = Input(shape=(None, num_features))\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = Input(shape=(None, num_features))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_features, activation='linear')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# encoder_input_data & decoder_input_data into decoder_target_data\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1548.6641 - val_loss: 1542.0903\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1542.0903 - val_loss: 1535.9143\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1535.9144 - val_loss: 1530.0850\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1530.0851 - val_loss: 1524.5430\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1524.5430 - val_loss: 1519.2385\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1519.2384 - val_loss: 1514.1326\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1514.1324 - val_loss: 1509.1918\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1509.1918 - val_loss: 1504.3862\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1504.3862 - val_loss: 1499.6866\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1499.6869 - val_loss: 1495.0649\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1495.0649 - val_loss: 1490.4943\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1490.4941 - val_loss: 1485.9512\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1485.9512 - val_loss: 1481.4153\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1481.4152 - val_loss: 1476.8662\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1476.8662 - val_loss: 1472.2836\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1472.2836 - val_loss: 1467.6486\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1467.6486 - val_loss: 1462.9476\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1462.9476 - val_loss: 1458.1713\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1458.1713 - val_loss: 1453.3127\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1453.3129 - val_loss: 1448.3685\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1448.3685 - val_loss: 1443.3398\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1443.3398 - val_loss: 1438.2338\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1438.2339 - val_loss: 1433.0627\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1433.0629 - val_loss: 1427.8408\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1427.8408 - val_loss: 1422.5802\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1422.5802 - val_loss: 1417.2896\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1417.2896 - val_loss: 1411.9729\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1411.9730 - val_loss: 1406.6317\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1406.6317 - val_loss: 1401.2655\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1401.2655 - val_loss: 1395.8755\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1395.8755 - val_loss: 1390.4740\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1390.4740 - val_loss: 1385.0828\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1385.0829 - val_loss: 1379.7148\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1379.7148 - val_loss: 1374.3688\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1374.3688 - val_loss: 1369.0387\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1369.0387 - val_loss: 1363.7190\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1363.7190 - val_loss: 1358.4020\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1358.4020 - val_loss: 1353.0762\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1353.0763 - val_loss: 1347.7273\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1347.7272 - val_loss: 1342.3391\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1342.3392 - val_loss: 1336.8987\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1336.8987 - val_loss: 1331.3973\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1331.3973 - val_loss: 1325.8317\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1325.8317 - val_loss: 1320.2012\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1320.2012 - val_loss: 1314.5059\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1314.5059 - val_loss: 1308.7437\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1308.7438 - val_loss: 1302.9119\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1302.9117 - val_loss: 1297.0059\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1297.0060 - val_loss: 1291.0229\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1291.0228 - val_loss: 1284.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x249b740a680>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training data\n",
    "encoder_input_data = inputs\n",
    "decoder_input_data = np.zeros_like(targets)\n",
    "decoder_input_data[:, 1:, :] = targets[:, :-1, :]  # Shifted target sequences\n",
    "decoder_target_data = targets\n",
    "\n",
    "# Train the model\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=64, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Decoded sequence: [[3.389219  3.5514295 4.4847946]\n",
      " [3.8782923 4.0184774 4.7389703]\n",
      " [3.9243848 4.3190184 4.7797847]\n",
      " [3.861138  4.4353952 4.760472 ]]\n"
     ]
    }
   ],
   "source": [
    "# Define the encoder model for inference\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Define the decoder model for inference\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Function to generate sequences\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate an empty target sequence\n",
    "    target_seq = np.zeros((1, 1, num_features))\n",
    "\n",
    "    # Populate the first element with a start token\n",
    "    target_seq[0, 0, :] = [0, 0, 0]\n",
    "\n",
    "    # Sampling loop\n",
    "    stop_condition = False\n",
    "    decoded_sequence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Append the predicted token to the decoded sequence\n",
    "        decoded_sequence.append(output_tokens[0, 0, :])\n",
    "\n",
    "        # Exit condition\n",
    "        if len(decoded_sequence) >= input_seq.shape[1]:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence\n",
    "        target_seq = np.zeros((1, 1, num_features))\n",
    "        target_seq[0, 0, :] = output_tokens[0, 0, :]\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return np.array(decoded_sequence)\n",
    "\n",
    "# Example usage\n",
    "test_input = encoder_input_data[0:1]  # Replace with actual test input\n",
    "decoded_sequence = decode_sequence(test_input)\n",
    "print(\"Decoded sequence:\", decoded_sequence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
